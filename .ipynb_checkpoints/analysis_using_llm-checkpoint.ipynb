{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fa5adf-139a-47c1-b6e5-955a844f06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-09 14:55:22] [INFO] ======================================================================\n",
      "[2026-02-09 14:55:22] [INFO] GENDER BIAS ANALYSIS - STARTED\n",
      "[2026-02-09 14:55:22] [INFO] Configuration: 1 stories\n",
      "[2026-02-09 14:55:22] [INFO] ======================================================================\n",
      "[2026-02-09 14:55:22] [INFO] Loading data from samentic_chunk.csv\n",
      "[2026-02-09 14:55:22] [INFO] ✓ Stories selected: 1\n",
      "[2026-02-09 14:55:22] [INFO] ✓ Total chunks: 61\n",
      "[2026-02-09 14:55:22] [INFO] Story titles: ['A DESCENT INTO THE MAELSTRÖM']\n",
      "[2026-02-09 14:55:22] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:22] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 0\n",
      "[2026-02-09 14:55:22] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:28] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:55:28] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:28] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 1\n",
      "[2026-02-09 14:55:28] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:30] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:55:30] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:30] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 2\n",
      "[2026-02-09 14:55:30] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:31] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:55:31] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:31] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 3\n",
      "[2026-02-09 14:55:31] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:34] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:55:34] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:34] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 4\n",
      "[2026-02-09 14:55:34] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:34] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:34] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:34] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 5\n",
      "[2026-02-09 14:55:34] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:35] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:35] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:35] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 6\n",
      "[2026-02-09 14:55:35] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:36] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:36] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:36] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 7\n",
      "[2026-02-09 14:55:36] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:41] [WARNING] JSON truncated at position 282, attempting repair...\n",
      "[2026-02-09 14:55:41] [WARNING] Repaired by removing incomplete character entry\n",
      "[2026-02-09 14:55:41] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:41] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:41] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 8\n",
      "[2026-02-09 14:55:41] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:42] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:42] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:42] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 9\n",
      "[2026-02-09 14:55:42] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:44] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:44] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:44] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 10\n",
      "[2026-02-09 14:55:44] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:48] [INFO] ✓ Extracted 4 characters\n",
      "[2026-02-09 14:55:48] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:48] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 11\n",
      "[2026-02-09 14:55:48] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:48] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:48] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:48] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 12\n",
      "[2026-02-09 14:55:48] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:49] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:49] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:49] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 13\n",
      "[2026-02-09 14:55:49] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:51] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:51] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:51] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 14\n",
      "[2026-02-09 14:55:51] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:53] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:55:53] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:53] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 15\n",
      "[2026-02-09 14:55:53] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:54] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:54] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:54] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 16\n",
      "[2026-02-09 14:55:54] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:56] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:55:56] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:56] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 17\n",
      "[2026-02-09 14:55:56] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:55:57] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:55:57] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:55:57] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 18\n",
      "[2026-02-09 14:55:57] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:00] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:00] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:00] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 19\n",
      "[2026-02-09 14:56:00] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:04] [INFO] ✓ Extracted 3 characters\n",
      "[2026-02-09 14:56:04] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:04] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 20\n",
      "[2026-02-09 14:56:04] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:09] [INFO] ✓ Extracted 4 characters\n",
      "[2026-02-09 14:56:09] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:09] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 21\n",
      "[2026-02-09 14:56:09] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:14] [INFO] ✓ Extracted 4 characters\n",
      "[2026-02-09 14:56:14] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:14] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 22\n",
      "[2026-02-09 14:56:14] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:15] [WARNING] JSON truncated at position 238, attempting repair...\n",
      "[2026-02-09 14:56:15] [WARNING] Repaired by removing incomplete character entry\n",
      "[2026-02-09 14:56:15] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:56:15] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:15] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 23\n",
      "[2026-02-09 14:56:15] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:18] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:18] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:18] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 24\n",
      "[2026-02-09 14:56:18] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:24] [INFO] ✓ Extracted 4 characters\n",
      "[2026-02-09 14:56:24] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:24] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 25\n",
      "[2026-02-09 14:56:24] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:26] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:26] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:26] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 26\n",
      "[2026-02-09 14:56:26] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:29] [INFO] ✓ Extracted 3 characters\n",
      "[2026-02-09 14:56:29] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:29] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 27\n",
      "[2026-02-09 14:56:29] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:31] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:31] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:31] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 28\n",
      "[2026-02-09 14:56:31] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:34] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:34] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:34] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 29\n",
      "[2026-02-09 14:56:34] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:37] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:37] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:37] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 30\n",
      "[2026-02-09 14:56:37] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:39] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:39] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:39] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 31\n",
      "[2026-02-09 14:56:39] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:41] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:41] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:41] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 32\n",
      "[2026-02-09 14:56:41] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:43] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:43] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:43] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 33\n",
      "[2026-02-09 14:56:43] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:45] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:45] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:45] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 34\n",
      "[2026-02-09 14:56:45] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:47] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:56:47] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:47] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 35\n",
      "[2026-02-09 14:56:47] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:49] [WARNING] JSON truncated at position 210, attempting repair...\n",
      "[2026-02-09 14:56:49] [WARNING] Repaired by removing incomplete character entry\n",
      "[2026-02-09 14:56:49] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:56:49] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:49] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 36\n",
      "[2026-02-09 14:56:49] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:51] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:51] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:51] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 37\n",
      "[2026-02-09 14:56:51] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:52] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:52] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:52] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 38\n",
      "[2026-02-09 14:56:52] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:54] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:54] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:54] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 39\n",
      "[2026-02-09 14:56:54] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:56] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:56] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:56] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 40\n",
      "[2026-02-09 14:56:56] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:56:58] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:56:58] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:56:58] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 41\n",
      "[2026-02-09 14:56:58] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:00] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:00] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:00] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 42\n",
      "[2026-02-09 14:57:00] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:01] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:57:01] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:01] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 43\n",
      "[2026-02-09 14:57:01] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:04] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:04] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:04] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 44\n",
      "[2026-02-09 14:57:04] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:06] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:06] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:06] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 45\n",
      "[2026-02-09 14:57:06] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:08] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:08] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:08] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 46\n",
      "[2026-02-09 14:57:08] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:10] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:10] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:10] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 47\n",
      "[2026-02-09 14:57:10] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:13] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:13] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:13] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 48\n",
      "[2026-02-09 14:57:13] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:15] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:15] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:15] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 49\n",
      "[2026-02-09 14:57:15] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:16] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:57:16] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:16] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 50\n",
      "[2026-02-09 14:57:16] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:18] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:18] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:18] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 51\n",
      "[2026-02-09 14:57:18] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:19] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:19] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:19] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 52\n",
      "[2026-02-09 14:57:19] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:21] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:21] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:21] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 53\n",
      "[2026-02-09 14:57:21] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:22] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:57:22] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:22] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 54\n",
      "[2026-02-09 14:57:22] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:23] [INFO] ✓ Extracted 0 characters\n",
      "[2026-02-09 14:57:23] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:23] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 55\n",
      "[2026-02-09 14:57:23] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:26] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:26] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:26] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 56\n",
      "[2026-02-09 14:57:26] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:28] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:28] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:28] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 57\n",
      "[2026-02-09 14:57:28] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:31] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:31] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:31] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 58\n",
      "[2026-02-09 14:57:31] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:33] [INFO] ✓ Extracted 2 characters\n",
      "[2026-02-09 14:57:33] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:33] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 59\n",
      "[2026-02-09 14:57:33] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:35] [INFO] ✓ Extracted 1 characters\n",
      "[2026-02-09 14:57:35] [INFO] ----------------------------------------------------------------------\n",
      "[2026-02-09 14:57:35] [INFO] Processing: A DESCENT INTO THE MAELSTRÖM | Chunk 60\n",
      "[2026-02-09 14:57:35] [INFO] Calling OpenAI API...\n",
      "[2026-02-09 14:57:38] [INFO] ✓ Extracted 3 characters\n",
      "[2026-02-09 14:57:38] [INFO] ✓ Raw results saved: analysis_results/raw_characters_20260209_145521.csv\n",
      "[2026-02-09 14:57:38] [INFO] Computing bias statistics...\n",
      "[2026-02-09 14:57:38] [INFO] ✓ Bias analysis saved: analysis_results/bias_summary_20260209_145521.csv\n",
      "[2026-02-09 14:57:38] [INFO] ======================================================================\n",
      "[2026-02-09 14:57:38] [INFO] BIAS SUMMARY:\n",
      "[2026-02-09 14:57:38] [INFO] ======================================================================\n",
      "[2026-02-09 14:57:38] [INFO] \n",
      "gender  character_count  percentage  intelligence_mean  intelligence_std  intelligence_median  bravery_mean  bravery_std  bravery_median  power_mean  power_std  power_median  agency_mean  agency_std  agency_median  emotionality_mean  emotionality_std  emotionality_median\n",
      "female                1       100.0                0.0               NaN                  0.0           0.0          NaN             0.0         0.0        NaN           0.0          0.0         NaN            0.0                1.0               NaN                  1.0\n",
      "[2026-02-09 14:57:38] [INFO] ======================================================================\n",
      "[2026-02-09 14:57:38] [INFO] KEY FINDINGS:\n",
      "[2026-02-09 14:57:38] [INFO] Total characters analyzed: 77\n",
      "[2026-02-09 14:57:38] [INFO]   unknown: 76 (98.7%)\n",
      "[2026-02-09 14:57:38] [INFO]   female: 1 (1.3%)\n",
      "[2026-02-09 14:57:38] [INFO] ======================================================================\n",
      "[2026-02-09 14:57:38] [INFO] PROCESSING COMPLETE\n",
      "[2026-02-09 14:57:38] [INFO] ======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "GENDER BIAS PATTERN ANALYSIS IN NARRATIVE TEXT\n",
    "=============================================================================\n",
    "Author: Data Research Engineer\n",
    "Purpose: Detect and quantify gender representation and trait attribution bias\n",
    "         in story narratives using LLM-based extraction\n",
    "\n",
    "Key Features:\n",
    "- Adaptive character extraction (not limited to 4 slots)\n",
    "- Comprehensive trait analysis\n",
    "- Statistical aggregation\n",
    "- Robust error handling\n",
    "- Detailed logging\n",
    "\n",
    "Research Questions:\n",
    "1. Are male/female characters represented equally?\n",
    "2. Do male/female characters receive different trait attributions?\n",
    "3. Are power/intelligence/bravery scored differently by gender?\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "# =====================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================\n",
    "class Config:\n",
    "    # Processing settings\n",
    "    NUM_STORIES = 1  # Start with 1, can increase to 2, 5, 10, 60, etc.\n",
    "    INPUT_CSV = \"samentic_chunk.csv\"\n",
    "    OUTPUT_DIR = \"analysis_results\"\n",
    "    \n",
    "    # Output files\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    RAW_OUTPUT = f\"{OUTPUT_DIR}/raw_characters_{TIMESTAMP}.csv\"\n",
    "    AGGREGATED_OUTPUT = f\"{OUTPUT_DIR}/bias_summary_{TIMESTAMP}.csv\"\n",
    "    LOG_FILE = f\"{OUTPUT_DIR}/processing_log_{TIMESTAMP}.txt\"\n",
    "    \n",
    "    # LLM settings\n",
    "    MODEL = \"gpt-4.1-nano\"\n",
    "    TEMPERATURE = 0.1\n",
    "    MAX_TOKENS = 3500\n",
    "    \n",
    "    # Analysis dimensions\n",
    "    DIMENSIONS = [\"intelligence\", \"bravery\", \"power\", \"agency\", \"emotionality\"]\n",
    "\n",
    "# =====================================================\n",
    "# LOGGING\n",
    "# =====================================================\n",
    "class Logger:\n",
    "    def __init__(self, log_file: str):\n",
    "        import os\n",
    "        os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "        self.log_file = log_file\n",
    "        \n",
    "    def log(self, message: str, level: str = \"INFO\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_message = f\"[{timestamp}] [{level}] {message}\"\n",
    "        print(log_message)\n",
    "        \n",
    "        with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(log_message + \"\\n\")\n",
    "\n",
    "# =====================================================\n",
    "# OPENAI CLIENT\n",
    "# =====================================================\n",
    "client = OpenAI()\n",
    "\n",
    "# =====================================================\n",
    "# IMPROVED PROMPT - RESEARCH-GRADE\n",
    "# =====================================================\n",
    "def build_analysis_prompt(title: str, chunk_id: int, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Research-grade prompt for unbiased character analysis\n",
    "    \n",
    "    Key improvements:\n",
    "    - Clear definition of evidence levels\n",
    "    - Flexible character count\n",
    "    - Multiple trait dimensions\n",
    "    - Explicit gender identification rules\n",
    "    \"\"\"\n",
    "    \n",
    "    return f\"\"\"You are analyzing narrative text for gender representation research.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. ONLY analyze the text provided below - no external knowledge\n",
    "2. Gender identification: ONLY if explicitly stated (he/she/him/her or direct statements like \"the woman\" or \"the man\")\n",
    "3. Count each distinct person separately\n",
    "4. If gender is ambiguous or unstated, mark as \"unknown\"\n",
    "\n",
    "TASK: Extract ALL characters mentioned in this text chunk.\n",
    "\n",
    "For EACH character, provide:\n",
    "- name: Character's name or description (e.g., \"the merchant\", \"Anna\", \"unnamed soldier\")\n",
    "- gender: \"male\", \"female\", or \"unknown\" (ONLY based on explicit evidence)\n",
    "- traits: List of character traits explicitly shown (e.g., [\"brave\", \"intelligent\", \"cruel\"])\n",
    "- scores: Rate these dimensions based on EXPLICIT evidence in the text:\n",
    "\n",
    "SCORING SYSTEM:\n",
    "+2 = Strongly demonstrated (multiple clear examples)\n",
    "+1 = Demonstrated (one clear example)\n",
    " 0 = No evidence or neutral\n",
    "-1 = Contradicted (shown to lack this trait)\n",
    "-2 = Strongly contradicted (multiple examples of lacking trait)\n",
    "\n",
    "DIMENSIONS TO SCORE:\n",
    "- intelligence: Problem-solving, knowledge, wisdom, strategic thinking\n",
    "- bravery: Courage, facing danger, taking risks\n",
    "- power: Authority, control, influence over others or events\n",
    "- agency: Making decisions, driving the plot, acting independently\n",
    "- emotionality: Expressing feelings, being emotional (not negative - just presence)\n",
    "\n",
    "OUTPUT FORMAT (JSON):\n",
    "{{\n",
    "  \"chunk_summary\": \"Brief 1-sentence summary\",\n",
    "  \"total_characters\": number,\n",
    "  \"characters\": [\n",
    "    {{\n",
    "      \"name\": \"character name\",\n",
    "      \"gender\": \"male\" | \"female\" | \"unknown\",\n",
    "      \"traits\": [\"trait1\", \"trait2\"],\n",
    "      \"scores\": {{\n",
    "        \"intelligence\": -2 to +2,\n",
    "        \"bravery\": -2 to +2,\n",
    "        \"power\": -2 to +2,\n",
    "        \"agency\": -2 to +2,\n",
    "        \"emotionality\": -2 to +2\n",
    "      }}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "CRITICAL OUTPUT RULES:\n",
    "- MUST return complete, valid JSON only\n",
    "- If 0 characters: \"characters\": []\n",
    "- Keep chunk_summary under 15 words\n",
    "- Keep name under 20 characters  \n",
    "- Maximum 5 traits per character\n",
    "- NO evidence field - removed to prevent truncation\n",
    "- NO markdown, NO explanations\n",
    "- MUST close all brackets and braces\n",
    "- When uncertain, score 0\n",
    "\n",
    "STORY CHUNK TO ANALYZE:\n",
    "Title: {title}\n",
    "Chunk ID: {chunk_id}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "JSON OUTPUT:\"\"\"\n",
    "\n",
    "# =====================================================\n",
    "# LLM INTERACTION\n",
    "# =====================================================\n",
    "def call_llm(prompt: str, logger: Logger) -> str:\n",
    "    \"\"\"Call OpenAI API with error handling\"\"\"\n",
    "    try:\n",
    "        logger.log(\"Calling OpenAI API...\")\n",
    "        \n",
    "        response = client.responses.create(\n",
    "            model=Config.MODEL,\n",
    "            input=prompt,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_output_tokens=Config.MAX_TOKENS\n",
    "        )\n",
    "        \n",
    "        return response.output_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.log(f\"API Error: {str(e)}\", \"ERROR\")\n",
    "        raise\n",
    "\n",
    "# =====================================================\n",
    "# JSON EXTRACTION & VALIDATION\n",
    "# =====================================================\n",
    "def extract_and_validate_json(text: str, logger: Logger) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract JSON from LLM response with robust error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove markdown if present\n",
    "        text = text.strip()\n",
    "        if text.startswith(\"```\"):\n",
    "            text = text.split(\"```\")[1]\n",
    "            if text.startswith(\"json\"):\n",
    "                text = text[4:]\n",
    "        \n",
    "        # Find JSON boundaries\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\") + 1\n",
    "        \n",
    "        if start == -1 or end == 0:\n",
    "            raise ValueError(\"No JSON found in response\")\n",
    "        \n",
    "        json_str = text[start:end]\n",
    "        \n",
    "        # First attempt: parse as-is\n",
    "        try:\n",
    "            parsed = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # If truncated, try to recover\n",
    "            logger.log(f\"JSON truncated at position {e.pos}, attempting repair...\", \"WARNING\")\n",
    "            \n",
    "            # Strategy: Find last complete character and close the JSON properly\n",
    "            if '\"characters\"' in json_str:\n",
    "                # Find the start of the last character that begins properly\n",
    "                last_complete = -1\n",
    "                char_pattern = '\"name\"'\n",
    "                pos = 0\n",
    "                while True:\n",
    "                    pos = json_str.find(char_pattern, pos)\n",
    "                    if pos == -1:\n",
    "                        break\n",
    "                    # Check if this character is complete (has closing brace before error)\n",
    "                    if pos < e.pos:\n",
    "                        last_complete = pos\n",
    "                    pos += 1\n",
    "                \n",
    "                if last_complete > 0:\n",
    "                    # Find the opening brace of this character\n",
    "                    brace_pos = json_str.rfind('{', 0, last_complete)\n",
    "                    if brace_pos > 0:\n",
    "                        # Truncate before the incomplete character\n",
    "                        json_str = json_str[:brace_pos].rstrip().rstrip(',') + ']}'\n",
    "                        logger.log(\"Repaired by removing incomplete character entry\", \"WARNING\")\n",
    "                        parsed = json.loads(json_str)\n",
    "                    else:\n",
    "                        # No complete characters, return empty\n",
    "                        parsed = {\"chunk_summary\": \"Parse error\", \"total_characters\": 0, \"characters\": []}\n",
    "                        logger.log(\"No complete characters found, returning empty\", \"WARNING\")\n",
    "                else:\n",
    "                    # No complete characters found\n",
    "                    parsed = {\"chunk_summary\": \"Parse error\", \"total_characters\": 0, \"characters\": []}\n",
    "                    logger.log(\"No complete characters found, returning empty\", \"WARNING\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Validate structure\n",
    "        required_keys = {\"chunk_summary\", \"total_characters\", \"characters\"}\n",
    "        if not required_keys.issubset(parsed.keys()):\n",
    "            raise ValueError(f\"Missing required keys. Expected {required_keys}, got {parsed.keys()}\")\n",
    "        \n",
    "        # Validate each character\n",
    "        for i, char in enumerate(parsed[\"characters\"]):\n",
    "            char_keys = {\"name\", \"gender\", \"traits\", \"scores\"}\n",
    "            if not char_keys.issubset(char.keys()):\n",
    "                logger.log(f\"Character {i} missing keys. Filling with defaults.\", \"WARNING\")\n",
    "                \n",
    "                # Fill missing keys\n",
    "                if \"name\" not in char:\n",
    "                    char[\"name\"] = f\"character_{i}\"\n",
    "                if \"gender\" not in char:\n",
    "                    char[\"gender\"] = \"unknown\"\n",
    "                if \"traits\" not in char:\n",
    "                    char[\"traits\"] = []\n",
    "                if \"scores\" not in char:\n",
    "                    char[\"scores\"] = {}\n",
    "            # Validate scores\n",
    "            for dim in Config.DIMENSIONS:\n",
    "                if dim not in char[\"scores\"]:\n",
    "                    char[\"scores\"][dim] = 0\n",
    "                    \n",
    "        return parsed\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.log(f\"JSON Parse Error: {e}\", \"ERROR\")\n",
    "        logger.log(f\"Response preview: {text[:500]}\", \"ERROR\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.log(f\"Validation Error: {e}\", \"ERROR\")\n",
    "        raise\n",
    "\n",
    "# =====================================================\n",
    "# DATA FLATTENING\n",
    "# =====================================================\n",
    "def flatten_to_rows(result: Dict[str, Any], title: str, chunk_id: int) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert nested JSON to flat rows for CSV\n",
    "    Each character becomes a separate row\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for char in result[\"characters\"]:\n",
    "        row = {\n",
    "            \"title\": title,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"chunk_summary\": result[\"chunk_summary\"],\n",
    "            \"character_name\": char[\"name\"],\n",
    "            \"gender\": char[\"gender\"],\n",
    "            \"traits\": json.dumps(char[\"traits\"]),\n",
    "        }\n",
    "        \n",
    "        # Add dimension scores\n",
    "        for dim in Config.DIMENSIONS:\n",
    "            row[f\"score_{dim}\"] = char[\"scores\"].get(dim, 0)\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "# =====================================================\n",
    "# BIAS ANALYSIS\n",
    "# =====================================================\n",
    "def analyze_bias(df: pd.DataFrame, logger: Logger) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute aggregate statistics to reveal bias patterns\n",
    "    \"\"\"\n",
    "    logger.log(\"Computing bias statistics...\")\n",
    "    \n",
    "    # Filter out unknown gender for bias comparison\n",
    "    df_gendered = df[df[\"gender\"].isin([\"male\", \"female\"])]\n",
    "    \n",
    "    if len(df_gendered) == 0:\n",
    "        logger.log(\"No gendered characters found\", \"WARNING\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Group by gender and compute statistics\n",
    "    stats = []\n",
    "    \n",
    "    for gender in [\"male\", \"female\"]:\n",
    "        gender_df = df_gendered[df_gendered[\"gender\"] == gender]\n",
    "        \n",
    "        if len(gender_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        stat_row = {\n",
    "            \"gender\": gender,\n",
    "            \"character_count\": len(gender_df),\n",
    "            \"percentage\": len(gender_df) / len(df_gendered) * 100,\n",
    "        }\n",
    "        \n",
    "        # Average scores for each dimension\n",
    "        for dim in Config.DIMENSIONS:\n",
    "            scores = gender_df[f\"score_{dim}\"]\n",
    "            stat_row[f\"{dim}_mean\"] = scores.mean()\n",
    "            stat_row[f\"{dim}_std\"] = scores.std()\n",
    "            stat_row[f\"{dim}_median\"] = scores.median()\n",
    "        \n",
    "        stats.append(stat_row)\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    \n",
    "    # Add difference row (male - female)\n",
    "    if len(stats_df) == 2:\n",
    "        diff_row = {\"gender\": \"difference (male - female)\"}\n",
    "        \n",
    "        male_stats = stats_df[stats_df[\"gender\"] == \"male\"].iloc[0]\n",
    "        female_stats = stats_df[stats_df[\"gender\"] == \"female\"].iloc[0]\n",
    "        \n",
    "        diff_row[\"character_count\"] = male_stats[\"character_count\"] - female_stats[\"character_count\"]\n",
    "        diff_row[\"percentage\"] = male_stats[\"percentage\"] - female_stats[\"percentage\"]\n",
    "        \n",
    "        for dim in Config.DIMENSIONS:\n",
    "            diff_row[f\"{dim}_mean\"] = male_stats[f\"{dim}_mean\"] - female_stats[f\"{dim}_mean\"]\n",
    "            diff_row[f\"{dim}_std\"] = None\n",
    "            diff_row[f\"{dim}_median\"] = male_stats[f\"{dim}_median\"] - female_stats[f\"{dim}_median\"]\n",
    "        \n",
    "        stats_df = pd.concat([stats_df, pd.DataFrame([diff_row])], ignore_index=True)\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# =====================================================\n",
    "# MAIN PIPELINE\n",
    "# =====================================================\n",
    "def process_stories():\n",
    "    \"\"\"\n",
    "    Main processing pipeline with comprehensive error handling\n",
    "    \"\"\"\n",
    "    # Initialize\n",
    "    import os\n",
    "    os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    logger = Logger(Config.LOG_FILE)\n",
    "    logger.log(\"=\"*70)\n",
    "    logger.log(\"GENDER BIAS ANALYSIS - STARTED\")\n",
    "    logger.log(f\"Configuration: {Config.NUM_STORIES} stories\")\n",
    "    logger.log(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        logger.log(f\"Loading data from {Config.INPUT_CSV}\")\n",
    "        df = pd.read_csv(Config.INPUT_CSV)\n",
    "        \n",
    "        # Select stories\n",
    "        selected_titles = df[\"title\"].unique()[:Config.NUM_STORIES]\n",
    "        df = df[df[\"title\"].isin(selected_titles)]\n",
    "        df = df.sort_values([\"title\", \"chunk_id\"])\n",
    "        \n",
    "        logger.log(f\"✓ Stories selected: {len(selected_titles)}\")\n",
    "        logger.log(f\"✓ Total chunks: {len(df)}\")\n",
    "        logger.log(f\"Story titles: {list(selected_titles)}\")\n",
    "        \n",
    "        # Process each chunk\n",
    "        all_characters = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            logger.log(\"-\" * 70)\n",
    "            logger.log(f\"Processing: {row['title']} | Chunk {row['chunk_id']}\")\n",
    "            \n",
    "            try:\n",
    "                # Build prompt\n",
    "                prompt = build_analysis_prompt(\n",
    "                    title=row[\"title\"],\n",
    "                    chunk_id=row[\"chunk_id\"],\n",
    "                    text=row[\"chunk_text\"]\n",
    "                )\n",
    "                \n",
    "                # Call LLM\n",
    "                response = call_llm(prompt, logger)\n",
    "                \n",
    "                # Parse and validate\n",
    "                result = extract_and_validate_json(response, logger)\n",
    "                \n",
    "                # Convert to rows\n",
    "                rows = flatten_to_rows(result, row[\"title\"], row[\"chunk_id\"])\n",
    "                all_characters.extend(rows)\n",
    "                \n",
    "                logger.log(f\"✓ Extracted {len(rows)} characters\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.log(f\"✗ Failed to process chunk: {str(e)}\", \"ERROR\")\n",
    "                logger.log(traceback.format_exc(), \"ERROR\")\n",
    "                continue\n",
    "        \n",
    "        # Save raw results\n",
    "        if len(all_characters) > 0:\n",
    "            characters_df = pd.DataFrame(all_characters)\n",
    "            characters_df.to_csv(Config.RAW_OUTPUT, index=False)\n",
    "            logger.log(f\"✓ Raw results saved: {Config.RAW_OUTPUT}\")\n",
    "            \n",
    "            # Compute bias statistics\n",
    "            bias_stats = analyze_bias(characters_df, logger)\n",
    "            \n",
    "            if len(bias_stats) > 0:\n",
    "                bias_stats.to_csv(Config.AGGREGATED_OUTPUT, index=False)\n",
    "                logger.log(f\"✓ Bias analysis saved: {Config.AGGREGATED_OUTPUT}\")\n",
    "                \n",
    "                # Print summary\n",
    "                logger.log(\"=\"*70)\n",
    "                logger.log(\"BIAS SUMMARY:\")\n",
    "                logger.log(\"=\"*70)\n",
    "                logger.log(\"\\n\" + bias_stats.to_string(index=False))\n",
    "            \n",
    "            # Print key findings\n",
    "            logger.log(\"=\"*70)\n",
    "            logger.log(\"KEY FINDINGS:\")\n",
    "            logger.log(f\"Total characters analyzed: {len(characters_df)}\")\n",
    "            \n",
    "            gender_counts = characters_df[\"gender\"].value_counts()\n",
    "            for gender, count in gender_counts.items():\n",
    "                logger.log(f\"  {gender}: {count} ({count/len(characters_df)*100:.1f}%)\")\n",
    "            \n",
    "        else:\n",
    "            logger.log(\"No characters extracted\", \"WARNING\")\n",
    "        \n",
    "        logger.log(\"=\"*70)\n",
    "        logger.log(\"PROCESSING COMPLETE\")\n",
    "        logger.log(\"=\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.log(f\"CRITICAL ERROR: {str(e)}\", \"ERROR\")\n",
    "        logger.log(traceback.format_exc(), \"ERROR\")\n",
    "        raise\n",
    "\n",
    "# =====================================================\n",
    "# RUN\n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    process_stories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfebec-ad97-449d-baef-b2c19d63e992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
